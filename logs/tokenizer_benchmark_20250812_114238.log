====================================================================================================
üöÄ TOKENIZER BENCHMARK SESSION STARTED
====================================================================================================
üìÖ Timestamp: 2025-08-12 11:42:38.473577
üìù Log file: logs/tokenizer_benchmark_20250812_114238.log
üêç Python version: 3.13.5 (v3.13.5:6cb20a219a8, Jun 11 2025, 12:23:45) [Clang 16.0.0 (clang-1600.0.26.6)]
üíª Working directory: /Users/aadisaraf/Documents/hyperMamba
====================================================================================================

====================================================================================================
üî• SECTION START: COMPREHENSIVE BENCHMARK
üìã Description: Full industry-standard tokenizer evaluation suite
‚è∞ Started at: 11:42:38
====================================================================================================
üè¢ OFFICIAL INDUSTRY-STANDARD TOKENIZER BENCHMARK SUITE
================================================================================
Comprehensive evaluation using methodologies from tech giants
Based on research from OpenAI, Google, Meta, and academic institutions
================================================================================

====================================================================================================
üî• SECTION START: COMPRESSION BENCHMARK
üìã Description: Testing compression efficiency vs reference tokenizer
‚è∞ Started at: 11:42:38
====================================================================================================
================================================================================
üìä COMPRESSION EFFICIENCY BENCHMARK
================================================================================
Primary metric used by OpenAI, Google, Meta for tokenizer evaluation
Test 1: The quick brown fox jumps over the lazy dog repeatedly and e...
  Reference (tiktoken)     ‚Üí Tokens:  13, Time:  0.27ms
  HyperTokenizer16k        ‚Üí Tokens:  11, Time:  0.02ms
  Compression Ratio: 0.846 ‚úÖ
Test 2: Natural language processing and artificial intelligence revo...
  Reference (tiktoken)     ‚Üí Tokens:  16, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  13, Time:  0.02ms
  Compression Ratio: 0.812 ‚úÖ
Test 3: In the realm of quantum computing, superposition and entangl...
  Reference (tiktoken)     ‚Üí Tokens:  18, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  17, Time:  0.03ms
  Compression Ratio: 0.944 ‚úÖ
Test 4: def fibonacci(n): return n if n <= 1 else fibonacci(n-1) + f...
  Reference (tiktoken)     ‚Üí Tokens:  23, Time:  0.03ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.02ms
  Compression Ratio: 0.609 ‚úÖ
Test 5: import torch; model = torch.nn.TransformerEncoder(layers=6, ...
  Reference (tiktoken)     ‚Üí Tokens:  20, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  16, Time:  0.02ms
  Compression Ratio: 0.800 ‚úÖ
Test 6: const apiResponse = await fetch('/api/users').then(res => re...
  Reference (tiktoken)     ‚Üí Tokens:  16, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  15, Time:  0.02ms
  Compression Ratio: 0.938 ‚úÖ
Test 7: public class DataProcessor { private final Config config; }
  Reference (tiktoken)     ‚Üí Tokens:  11, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:  10, Time:  0.01ms
  Compression Ratio: 0.909 ‚úÖ
Test 8: Visit https://www.example.com/docs/api/v2/reference for comp...
  Reference (tiktoken)     ‚Üí Tokens:  14, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:  17, Time:  0.02ms
  Compression Ratio: 1.214 ‚ùå
Test 9: <div class='container'><h1>Welcome</h1><p>Get started today!...
  Reference (tiktoken)     ‚Üí Tokens:  23, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:   8, Time:  0.01ms
  Compression Ratio: 0.348 ‚úÖ
Test 10: body { font-family: Arial, sans-serif; margin: 0; padding: 2...
  Reference (tiktoken)     ‚Üí Tokens:  22, Time:  0.06ms
  HyperTokenizer16k        ‚Üí Tokens:  19, Time:  0.02ms
  Compression Ratio: 0.864 ‚úÖ
Test 11: The algorithm achieves O(n log n) time complexity with optim...
  Reference (tiktoken)     ‚Üí Tokens:  14, Time:  0.03ms
  HyperTokenizer16k        ‚Üí Tokens:  16, Time:  0.02ms
  Compression Ratio: 1.143 ‚ùå
Test 12: Neural networks utilize backpropagation for gradient-based o...
  Reference (tiktoken)     ‚Üí Tokens:  12, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:  12, Time:  0.01ms
  Compression Ratio: 1.000 ‚ùå
Test 13: DNA sequences: ATCGATCGATCG, RNA transcription: AUCGAUCGAUCG
  Reference (tiktoken)     ‚Üí Tokens:  20, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  11, Time:  0.02ms
  Compression Ratio: 0.550 ‚úÖ
Test 14: SELECT * FROM users WHERE active = 1 ORDER BY created_at DES...
  Reference (tiktoken)     ‚Üí Tokens:  17, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  12, Time:  0.02ms
  Compression Ratio: 0.706 ‚úÖ
Test 15: {"name": "John", "age": 30, "email": "john@example.com", "ac...
  Reference (tiktoken)     ‚Üí Tokens:  25, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  22, Time:  0.02ms
  Compression Ratio: 0.880 ‚úÖ
Test 16: Version 2.1.3-beta.4 released with performance improvements ...
  Reference (tiktoken)     ‚Üí Tokens:  17, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:   8, Time:  0.01ms
  Compression Ratio: 0.471 ‚úÖ
Test 17: Processing 1,234,567 records at 99.7% accuracy with 0.003ms ...
  Reference (tiktoken)     ‚Üí Tokens:  23, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:  11, Time:  0.02ms
  Compression Ratio: 0.478 ‚úÖ
Test 18: User ID: usr_1234567890, Session: tok_abcdef123456, Expires:...
  Reference (tiktoken)     ‚Üí Tokens:  35, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  23, Time:  0.03ms
  Compression Ratio: 0.657 ‚úÖ
Test 19: Phone: +1-555-123-4567, Email: support@company.com, Website:...
  Reference (tiktoken)     ‚Üí Tokens:  25, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:  17, Time:  0.02ms
  Compression Ratio: 0.680 ‚úÖ
Test 20: Error 404: Page not found. Please check the URL https://exam...
  Reference (tiktoken)     ‚Üí Tokens:  22, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  25, Time:  0.03ms
  Compression Ratio: 1.136 ‚ùå
Test 21: Meeting scheduled for 2024-01-15 at 2:30 PM in Conference Ro...
  Reference (tiktoken)     ‚Üí Tokens:  27, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  22, Time:  0.03ms
  Compression Ratio: 0.815 ‚úÖ
Test 22: Log entry [2024-01-15 14:30:25] INFO: User authentication su...
  Reference (tiktoken)     ‚Üí Tokens:  26, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  22, Time:  0.03ms
  Compression Ratio: 0.846 ‚úÖ
============================================================
COMPRESSION BENCHMARK SUMMARY
============================================================
Total tests: 22
Success rate: 100.0%
Average compression ratio: 0.802
Median compression ratio: 0.830
Best compression ratio: 0.348
Worst compression ratio: 1.214
Average encode time: 0.02ms
üèÜ EXCELLENT: Significantly better compression than reference

‚úÖ SECTION END: COMPRESSION BENCHMARK
‚è∞ Completed at: 11:42:38
====================================================================================================


====================================================================================================
üî• SECTION START: SPEED BENCHMARK
üìã Description: Testing encoding/decoding performance
‚è∞ Started at: 11:42:38
====================================================================================================
================================================================================
‚ö° SPEED PERFORMANCE BENCHMARK
================================================================================
Critical metric for production deployment in tech companies
Test Name       Length   HyperTokenizer  Tiktoken     Speedup
----------------------------------------------------------------------
Short text      12       0.00            0.00         1.24      x
Medium text     440      0.01            0.03         2.14      x
Long text       2450     0.05            0.13         2.78      x
Code snippet    1220     0.04            0.13         2.91      x
JSON data       1200     0.04            0.14         3.65      x
URL heavy       1475     0.06            0.11         1.74      x
Mixed content   1095     0.03            0.09         2.94      x
============================================================
SPEED BENCHMARK SUMMARY
============================================================
Average speedup vs tiktoken: 2.49x
üèÜ EXCELLENT: Significantly faster than reference

‚úÖ SECTION END: SPEED BENCHMARK
‚è∞ Completed at: 11:42:38
====================================================================================================


====================================================================================================
üî• SECTION START: CHARACTER LEVEL BENCHMARK
üìã Description: Testing character-level reasoning and morphological alignment
‚è∞ Started at: 11:42:38
====================================================================================================
================================================================================
üî§ CHARACTER-LEVEL REASONING BENCHMARK (CharBench)
================================================================================
Based on academic research - tests character-level understanding
Task                      Word         Target   Expected   Tokens   Efficiency
--------------------------------------------------------------------------------
Count 'r' in 'strawberry' strawberry   r        3          1        3.00x
Count 'l' in 'hello'      hello        l        2          1        1.00x
Count 'a' in 'banana'     banana       a        3          1        1.00x
Count 's' in 'assessment' assessment   s        4          1        1.00x
Find first 'o' in 'hello' hello        o        4          1        1.00x
Find first 'a' in 'banana' banana       a        1          1        1.00x
Find first 'e' in 'development' development  e        1          1        1.00x
============================================================
CHARACTER-LEVEL BENCHMARK SUMMARY
============================================================
Lower token counts generally correlate with better character-level performance
This benchmark assesses tokenizer's suitability for character-aware tasks

‚úÖ SECTION END: CHARACTER LEVEL BENCHMARK
‚è∞ Completed at: 11:42:38
====================================================================================================


====================================================================================================
üî• SECTION START: ROBUSTNESS BENCHMARK
üìã Description: Testing edge case handling and domain robustness
‚è∞ Started at: 11:42:38
====================================================================================================
================================================================================
üõ°Ô∏è  ROBUSTNESS AND EDGE CASE BENCHMARK
================================================================================
Tests challenging inputs that commonly cause production failures
Test Case            Input                          Tokens   Success  Time (ms)
---------------------------------------------------------------------------
Multiple spaces      word1    word2    word3        5        ‚úÖ        0.03
Mixed whitespace     word1		word2
word3            5        ‚úÖ        0.04
Leading/trailing        leading and trailing        5        ‚úÖ        0.02
Unicode              caf√© na√Øve r√©sum√© üöÄ üéØ ‚úÖ        10       ‚úÖ        0.06
Punctuation heavy    Hello!!! What??? Yes... No-... 14       ‚úÖ        0.02
Mixed symbols        @#$%^&*()[]{}|\:;"'<>,./?      1        ‚úÖ        0.01
Repeated chars       aaaaaaaaaaaaaaaaaaaaaaaaaaa... 1        ‚úÖ        0.02
Long identifier      very_long_variable_name_tha... 1        ‚úÖ        0.01
Long URL             https://www.example.com/ver... 33       ‚úÖ        0.04
Empty string                                        0        ‚úÖ        0.00
Single char          a                              1        ‚úÖ        0.00
Single space                                        1        ‚úÖ        0.00
Large numbers        123456789012345678901234567890 1        ‚úÖ        0.01
Scientific notation  1.23e-45 6.78e+123             9        ‚úÖ        0.01
Mixed numeric        v1.2.3-beta.4+build.567.890    7        ‚úÖ        0.01
============================================================
ROBUSTNESS BENCHMARK SUMMARY
============================================================
Success rate: 100.0%
Average processing time: 0.02ms
üèÜ EXCELLENT: Highly robust tokenizer

‚úÖ SECTION END: ROBUSTNESS BENCHMARK
‚è∞ Completed at: 11:42:38
====================================================================================================


====================================================================================================
üî• SECTION START: FINAL ASSESSMENT
üìã Description: Overall benchmark results and grading
‚è∞ Started at: 11:42:38
====================================================================================================
================================================================================
üèÜ FINAL OVERALL ASSESSMENT
================================================================================
Overall compression ratio: 0.802
Overall success rate: 100.0%
üéØ FINAL GRADE: A+ (Industry Leading)
üìã RECOMMENDATIONS:
‚Ä¢ Excellent performance! Consider optimizing speed further
‚úÖ BENCHMARK COMPLETE - Results ready for production evaluation

‚úÖ SECTION END: FINAL ASSESSMENT
üìä Summary: Grade: A+ (Industry Leading), Tests: 22, Success Rate: 100.0% if 'overall_success_rate' in locals() else 'N/A'
‚è∞ Completed at: 11:42:38
====================================================================================================


‚úÖ SECTION END: COMPREHENSIVE BENCHMARK
üìä Summary: Completed 22 total tests
‚è∞ Completed at: 11:42:38
====================================================================================================

üìä Detailed results saved to: logs/benchmark_results_20250812_114238.json
Detailed results saved to JSON: logs/benchmark_results_20250812_114238.json

====================================================================================================
üéâ TOKENIZER BENCHMARK SESSION COMPLETED SUCCESSFULLY
====================================================================================================
üìä Total tests executed: 22
‚è∞ Session ended at: 2025-08-12 11:42:38.487791
üìù Log file: logs/tokenizer_benchmark_20250812_114238.log
====================================================================================================
