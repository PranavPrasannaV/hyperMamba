====================================================================================================
üöÄ TOKENIZER BENCHMARK SESSION STARTED
====================================================================================================
üìÖ Timestamp: 2025-08-12 11:56:10.781041
üìù Log file: logs/tokenizer_benchmark_20250812_115610.log
üêç Python version: 3.13.5 (v3.13.5:6cb20a219a8, Jun 11 2025, 12:23:45) [Clang 16.0.0 (clang-1600.0.26.6)]
üíª Working directory: /Users/aadisaraf/Documents/hyperMamba
====================================================================================================

====================================================================================================
üî• SECTION START: COMPREHENSIVE BENCHMARK
üìã Description: Full industry-standard tokenizer evaluation suite
‚è∞ Started at: 11:56:10
====================================================================================================
üè¢ OFFICIAL INDUSTRY-STANDARD TOKENIZER BENCHMARK SUITE
================================================================================
Comprehensive evaluation using methodologies from tech giants
Based on research from OpenAI, Google, Meta, and academic institutions
================================================================================

====================================================================================================
üî• SECTION START: COMPRESSION BENCHMARK
üìã Description: Testing compression efficiency vs reference tokenizer
‚è∞ Started at: 11:56:10
====================================================================================================
================================================================================
üìä COMPRESSION EFFICIENCY BENCHMARK
================================================================================
Primary metric used by OpenAI, Google, Meta for tokenizer evaluation
Test 1: The quick brown fox jumps over the lazy dog repeatedly and e...
  Reference (tiktoken)     ‚Üí Tokens:  13, Time:  0.35ms
  HyperTokenizer16k        ‚Üí Tokens:   8, Time:  0.03ms
  Compression Ratio: 0.615 ‚úÖ
Test 2: Natural language processing and artificial intelligence revo...
  Reference (tiktoken)     ‚Üí Tokens:  16, Time:  0.03ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.03ms
  Compression Ratio: 0.875 ‚úÖ
Test 3: In the realm of quantum computing, superposition and entangl...
  Reference (tiktoken)     ‚Üí Tokens:  18, Time:  0.04ms
  HyperTokenizer16k        ‚Üí Tokens:  11, Time:  0.07ms
  Compression Ratio: 0.611 ‚úÖ
Test 4: def fibonacci(n): return n if n <= 1 else fibonacci(n-1) + f...
  Reference (tiktoken)     ‚Üí Tokens:  23, Time:  0.05ms
  HyperTokenizer16k        ‚Üí Tokens:  13, Time:  0.02ms
  Compression Ratio: 0.565 ‚úÖ
Test 5: import torch; model = torch.nn.TransformerEncoder(layers=6, ...
  Reference (tiktoken)     ‚Üí Tokens:  20, Time:  0.03ms
  HyperTokenizer16k        ‚Üí Tokens:  15, Time:  0.03ms
  Compression Ratio: 0.750 ‚úÖ
Test 6: const apiResponse = await fetch('/api/users').then(res => re...
  Reference (tiktoken)     ‚Üí Tokens:  16, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  12, Time:  0.02ms
  Compression Ratio: 0.750 ‚úÖ
Test 7: public class DataProcessor { private final Config config; }
  Reference (tiktoken)     ‚Üí Tokens:  11, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:   6, Time:  0.01ms
  Compression Ratio: 0.545 ‚úÖ
Test 8: Visit https://www.example.com/docs/api/v2/reference for comp...
  Reference (tiktoken)     ‚Üí Tokens:  14, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.02ms
  Compression Ratio: 1.000 ‚ùå
Test 9: <div class='container'><h1>Welcome</h1><p>Get started today!...
  Reference (tiktoken)     ‚Üí Tokens:  23, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:   5, Time:  0.01ms
  Compression Ratio: 0.217 ‚úÖ
Test 10: body { font-family: Arial, sans-serif; margin: 0; padding: 2...
  Reference (tiktoken)     ‚Üí Tokens:  22, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.02ms
  Compression Ratio: 0.636 ‚úÖ
Test 11: The algorithm achieves O(n log n) time complexity with optim...
  Reference (tiktoken)     ‚Üí Tokens:  14, Time:  0.05ms
  HyperTokenizer16k        ‚Üí Tokens:   9, Time:  0.03ms
  Compression Ratio: 0.643 ‚úÖ
Test 12: Neural networks utilize backpropagation for gradient-based o...
  Reference (tiktoken)     ‚Üí Tokens:  12, Time:  0.08ms
  HyperTokenizer16k        ‚Üí Tokens:  10, Time:  0.02ms
  Compression Ratio: 0.833 ‚úÖ
Test 13: DNA sequences: ATCGATCGATCG, RNA transcription: AUCGAUCGAUCG
  Reference (tiktoken)     ‚Üí Tokens:  20, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:   6, Time:  0.02ms
  Compression Ratio: 0.300 ‚úÖ
Test 14: SELECT * FROM users WHERE active = 1 ORDER BY created_at DES...
  Reference (tiktoken)     ‚Üí Tokens:  17, Time:  0.03ms
  HyperTokenizer16k        ‚Üí Tokens:   9, Time:  0.03ms
  Compression Ratio: 0.529 ‚úÖ
Test 15: {"name": "John", "age": 30, "email": "john@example.com", "ac...
  Reference (tiktoken)     ‚Üí Tokens:  25, Time:  0.03ms
  HyperTokenizer16k        ‚Üí Tokens:  22, Time:  0.04ms
  Compression Ratio: 0.880 ‚úÖ
Test 16: Version 2.1.3-beta.4 released with performance improvements ...
  Reference (tiktoken)     ‚Üí Tokens:  17, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:   8, Time:  0.02ms
  Compression Ratio: 0.471 ‚úÖ
Test 17: Processing 1,234,567 records at 99.7% accuracy with 0.003ms ...
  Reference (tiktoken)     ‚Üí Tokens:  23, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:   7, Time:  0.02ms
  Compression Ratio: 0.304 ‚úÖ
Test 18: User ID: usr_1234567890, Session: tok_abcdef123456, Expires:...
  Reference (tiktoken)     ‚Üí Tokens:  35, Time:  0.03ms
  HyperTokenizer16k        ‚Üí Tokens:  15, Time:  0.03ms
  Compression Ratio: 0.429 ‚úÖ
Test 19: Phone: +1-555-123-4567, Email: support@company.com, Website:...
  Reference (tiktoken)     ‚Üí Tokens:  25, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.03ms
  Compression Ratio: 0.560 ‚úÖ
Test 20: Error 404: Page not found. Please check the URL https://exam...
  Reference (tiktoken)     ‚Üí Tokens:  22, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.03ms
  Compression Ratio: 0.636 ‚úÖ
Test 21: Meeting scheduled for 2024-01-15 at 2:30 PM in Conference Ro...
  Reference (tiktoken)     ‚Üí Tokens:  27, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  16, Time:  0.02ms
  Compression Ratio: 0.593 ‚úÖ
Test 22: Log entry [2024-01-15 14:30:25] INFO: User authentication su...
  Reference (tiktoken)     ‚Üí Tokens:  26, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  16, Time:  0.03ms
  Compression Ratio: 0.615 ‚úÖ
============================================================
COMPRESSION BENCHMARK SUMMARY
============================================================
Total tests: 22
Success rate: 100.0%
Average compression ratio: 0.607
Median compression ratio: 0.613
Best compression ratio: 0.217
Worst compression ratio: 1.000
Average encode time: 0.03ms
üèÜ EXCELLENT: Significantly better compression than reference

‚úÖ SECTION END: COMPRESSION BENCHMARK
‚è∞ Completed at: 11:56:10
====================================================================================================


====================================================================================================
üî• SECTION START: SPEED BENCHMARK
üìã Description: Testing encoding/decoding performance
‚è∞ Started at: 11:56:10
====================================================================================================
================================================================================
‚ö° SPEED PERFORMANCE BENCHMARK
================================================================================
Critical metric for production deployment in tech companies
Test Name       Length   HyperTokenizer  Tiktoken     Speedup
----------------------------------------------------------------------
Short text      12       0.00            0.00         1.52      x
Medium text     440      0.01            0.03         2.90      x
Long text       2450     0.04            0.12         3.33      x
Code snippet    1220     0.04            0.12         3.05      x
JSON data       1200     0.04            0.16         3.83      x
URL heavy       1475     0.04            0.13         3.55      x
Mixed content   1095     0.03            0.09         3.32      x
============================================================
SPEED BENCHMARK SUMMARY
============================================================
Average speedup vs tiktoken: 3.07x
üèÜ EXCELLENT: Significantly faster than reference

‚úÖ SECTION END: SPEED BENCHMARK
‚è∞ Completed at: 11:56:10
====================================================================================================


====================================================================================================
üî• SECTION START: CHARACTER LEVEL BENCHMARK
üìã Description: Testing character-level reasoning and morphological alignment
‚è∞ Started at: 11:56:10
====================================================================================================
================================================================================
üî§ CHARACTER-LEVEL REASONING BENCHMARK (CharBench)
================================================================================
Based on academic research - tests character-level understanding
Task                      Word         Target   Expected   Tokens   Efficiency
--------------------------------------------------------------------------------
Count 'r' in 'strawberry' strawberry   r        3          1        3.00x
Count 'l' in 'hello'      hello        l        2          1        1.00x
Count 'a' in 'banana'     banana       a        3          1        1.00x
Count 's' in 'assessment' assessment   s        4          1        1.00x
Find first 'o' in 'hello' hello        o        4          1        1.00x
Find first 'a' in 'banana' banana       a        1          1        1.00x
Find first 'e' in 'development' development  e        1          1        1.00x
============================================================
CHARACTER-LEVEL BENCHMARK SUMMARY
============================================================
Lower token counts generally correlate with better character-level performance
This benchmark assesses tokenizer's suitability for character-aware tasks

‚úÖ SECTION END: CHARACTER LEVEL BENCHMARK
‚è∞ Completed at: 11:56:10
====================================================================================================


====================================================================================================
üî• SECTION START: ROBUSTNESS BENCHMARK
üìã Description: Testing edge case handling and domain robustness
‚è∞ Started at: 11:56:10
====================================================================================================
================================================================================
üõ°Ô∏è  ROBUSTNESS AND EDGE CASE BENCHMARK
================================================================================
Tests challenging inputs that commonly cause production failures
Test Case            Input                          Tokens   Success  Time (ms)
---------------------------------------------------------------------------
Multiple spaces      word1    word2    word3        5        ‚úÖ        0.01
Mixed whitespace     word1		word2
word3            5        ‚úÖ        0.01
Leading/trailing        leading and trailing        4        ‚úÖ        0.01
Unicode              caf√© na√Øve r√©sum√© üöÄ üéØ ‚úÖ        6        ‚úÖ        0.22
Punctuation heavy    Hello!!! What??? Yes... No-... 14       ‚úÖ        0.02
Mixed symbols        @#$%^&*()[]{}|\:;"'<>,./?      1        ‚úÖ        0.01
Repeated chars       aaaaaaaaaaaaaaaaaaaaaaaaaaa... 1        ‚úÖ        0.02
Long identifier      very_long_variable_name_tha... 1        ‚úÖ        0.01
Long URL             https://www.example.com/ver... 32       ‚úÖ        0.03
Empty string                                        0        ‚úÖ        0.00
Single char          a                              1        ‚úÖ        0.00
Single space                                        1        ‚úÖ        0.00
Large numbers        123456789012345678901234567890 1        ‚úÖ        0.01
Scientific notation  1.23e-45 6.78e+123             9        ‚úÖ        0.01
Mixed numeric        v1.2.3-beta.4+build.567.890    5        ‚úÖ        0.01
============================================================
ROBUSTNESS BENCHMARK SUMMARY
============================================================
Success rate: 100.0%
Average processing time: 0.02ms
üèÜ EXCELLENT: Highly robust tokenizer
================================================================================
üß™ ADVANCED BENCHMARKS (Latency/Throughput/Efficiency/Scaling)
================================================================================
Token efficiency (compression ratio hyper/tiktoken): 0.719 ‚úÖ
Latency percentiles (seconds per batch; p50/p95/p99):
latency_small: hyper={'p50':0.000012,'p95':0.000017,'p99':0.000017}  tiktoken={'p50':0.000100,'p95':0.000108,'p99':0.000108}
latency_medium: hyper={'p50':0.000005,'p95':0.000007,'p99':0.000007}  tiktoken={'p50':0.001538,'p95':0.001637,'p99':0.001640}
latency_large: hyper={'p50':0.000028,'p95':0.000031,'p99':0.000031}  tiktoken={'p50':0.038917,'p95':0.039618,'p99':0.039635}
Throughput (mixed inputs) MB/s: hyper=2916.58, tiktoken=2.03
Throughput (many short) MB/s: hyper=120.24, tiktoken=7.57
Success + Determinism: hyper={'ok': True}, tiktoken={'ok': True}
Peak memory (bytes): hyper={'supported': False}, tiktoken={'supported': False}
