====================================================================================================
üöÄ TOKENIZER BENCHMARK SESSION STARTED
====================================================================================================
üìÖ Timestamp: 2025-08-12 11:57:12.133552
üìù Log file: logs/tokenizer_benchmark_20250812_115712.log
üêç Python version: 3.13.5 (v3.13.5:6cb20a219a8, Jun 11 2025, 12:23:45) [Clang 16.0.0 (clang-1600.0.26.6)]
üíª Working directory: /Users/aadisaraf/Documents/hyperMamba
====================================================================================================

====================================================================================================
üî• SECTION START: COMPREHENSIVE BENCHMARK
üìã Description: Full industry-standard tokenizer evaluation suite
‚è∞ Started at: 11:57:12
====================================================================================================
üè¢ OFFICIAL INDUSTRY-STANDARD TOKENIZER BENCHMARK SUITE
================================================================================
Comprehensive evaluation using methodologies from tech giants
Based on research from OpenAI, Google, Meta, and academic institutions
================================================================================

====================================================================================================
üî• SECTION START: COMPRESSION BENCHMARK
üìã Description: Testing compression efficiency vs reference tokenizer
‚è∞ Started at: 11:57:12
====================================================================================================
================================================================================
üìä COMPRESSION EFFICIENCY BENCHMARK
================================================================================
Primary metric used by OpenAI, Google, Meta for tokenizer evaluation
Test 1: The quick brown fox jumps over the lazy dog repeatedly and e...
  Reference (tiktoken)     ‚Üí Tokens:  13, Time:  0.30ms
  HyperTokenizer16k        ‚Üí Tokens:   8, Time:  0.03ms
  Compression Ratio: 0.615 ‚úÖ
Test 2: Natural language processing and artificial intelligence revo...
  Reference (tiktoken)     ‚Üí Tokens:  16, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.03ms
  Compression Ratio: 0.875 ‚úÖ
Test 3: In the realm of quantum computing, superposition and entangl...
  Reference (tiktoken)     ‚Üí Tokens:  18, Time:  0.03ms
  HyperTokenizer16k        ‚Üí Tokens:  11, Time:  0.02ms
  Compression Ratio: 0.611 ‚úÖ
Test 4: def fibonacci(n): return n if n <= 1 else fibonacci(n-1) + f...
  Reference (tiktoken)     ‚Üí Tokens:  23, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  13, Time:  0.02ms
  Compression Ratio: 0.565 ‚úÖ
Test 5: import torch; model = torch.nn.TransformerEncoder(layers=6, ...
  Reference (tiktoken)     ‚Üí Tokens:  20, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  15, Time:  0.02ms
  Compression Ratio: 0.750 ‚úÖ
Test 6: const apiResponse = await fetch('/api/users').then(res => re...
  Reference (tiktoken)     ‚Üí Tokens:  16, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:  12, Time:  0.02ms
  Compression Ratio: 0.750 ‚úÖ
Test 7: public class DataProcessor { private final Config config; }
  Reference (tiktoken)     ‚Üí Tokens:  11, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:   6, Time:  0.01ms
  Compression Ratio: 0.545 ‚úÖ
Test 8: Visit https://www.example.com/docs/api/v2/reference for comp...
  Reference (tiktoken)     ‚Üí Tokens:  14, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.02ms
  Compression Ratio: 1.000 ‚ùå
Test 9: <div class='container'><h1>Welcome</h1><p>Get started today!...
  Reference (tiktoken)     ‚Üí Tokens:  23, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:   5, Time:  0.01ms
  Compression Ratio: 0.217 ‚úÖ
Test 10: body { font-family: Arial, sans-serif; margin: 0; padding: 2...
  Reference (tiktoken)     ‚Üí Tokens:  22, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.02ms
  Compression Ratio: 0.636 ‚úÖ
Test 11: The algorithm achieves O(n log n) time complexity with optim...
  Reference (tiktoken)     ‚Üí Tokens:  14, Time:  0.03ms
  HyperTokenizer16k        ‚Üí Tokens:   9, Time:  0.02ms
  Compression Ratio: 0.643 ‚úÖ
Test 12: Neural networks utilize backpropagation for gradient-based o...
  Reference (tiktoken)     ‚Üí Tokens:  12, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  10, Time:  0.02ms
  Compression Ratio: 0.833 ‚úÖ
Test 13: DNA sequences: ATCGATCGATCG, RNA transcription: AUCGAUCGAUCG
  Reference (tiktoken)     ‚Üí Tokens:  20, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:   6, Time:  0.02ms
  Compression Ratio: 0.300 ‚úÖ
Test 14: SELECT * FROM users WHERE active = 1 ORDER BY created_at DES...
  Reference (tiktoken)     ‚Üí Tokens:  17, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:   9, Time:  0.03ms
  Compression Ratio: 0.529 ‚úÖ
Test 15: {"name": "John", "age": 30, "email": "john@example.com", "ac...
  Reference (tiktoken)     ‚Üí Tokens:  25, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  22, Time:  0.03ms
  Compression Ratio: 0.880 ‚úÖ
Test 16: Version 2.1.3-beta.4 released with performance improvements ...
  Reference (tiktoken)     ‚Üí Tokens:  17, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:   8, Time:  0.03ms
  Compression Ratio: 0.471 ‚úÖ
Test 17: Processing 1,234,567 records at 99.7% accuracy with 0.003ms ...
  Reference (tiktoken)     ‚Üí Tokens:  23, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:   7, Time:  0.02ms
  Compression Ratio: 0.304 ‚úÖ
Test 18: User ID: usr_1234567890, Session: tok_abcdef123456, Expires:...
  Reference (tiktoken)     ‚Üí Tokens:  35, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  15, Time:  0.03ms
  Compression Ratio: 0.429 ‚úÖ
Test 19: Phone: +1-555-123-4567, Email: support@company.com, Website:...
  Reference (tiktoken)     ‚Üí Tokens:  25, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.03ms
  Compression Ratio: 0.560 ‚úÖ
Test 20: Error 404: Page not found. Please check the URL https://exam...
  Reference (tiktoken)     ‚Üí Tokens:  22, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.03ms
  Compression Ratio: 0.636 ‚úÖ
Test 21: Meeting scheduled for 2024-01-15 at 2:30 PM in Conference Ro...
  Reference (tiktoken)     ‚Üí Tokens:  27, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  16, Time:  0.03ms
  Compression Ratio: 0.593 ‚úÖ
Test 22: Log entry [2024-01-15 14:30:25] INFO: User authentication su...
  Reference (tiktoken)     ‚Üí Tokens:  26, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  16, Time:  0.03ms
  Compression Ratio: 0.615 ‚úÖ
============================================================
COMPRESSION BENCHMARK SUMMARY
============================================================
Total tests: 22
Success rate: 100.0%
Average compression ratio: 0.607
Median compression ratio: 0.613
Best compression ratio: 0.217
Worst compression ratio: 1.000
Average encode time: 0.02ms
üèÜ EXCELLENT: Significantly better compression than reference

‚úÖ SECTION END: COMPRESSION BENCHMARK
‚è∞ Completed at: 11:57:12
====================================================================================================


====================================================================================================
üî• SECTION START: SPEED BENCHMARK
üìã Description: Testing encoding/decoding performance
‚è∞ Started at: 11:57:12
====================================================================================================
================================================================================
‚ö° SPEED PERFORMANCE BENCHMARK
================================================================================
Critical metric for production deployment in tech companies
Test Name       Length   HyperTokenizer  Tiktoken     Speedup
----------------------------------------------------------------------
Short text      12       0.00            0.00         1.93      x
Medium text     440      0.01            0.04         3.22      x
Long text       2450     0.04            0.12         3.01      x
Code snippet    1220     0.04            0.12         2.77      x
JSON data       1200     0.04            0.14         3.34      x
URL heavy       1475     0.05            0.11         2.34      x
Mixed content   1095     0.02            0.09         3.95      x
============================================================
SPEED BENCHMARK SUMMARY
============================================================
Average speedup vs tiktoken: 2.94x
üèÜ EXCELLENT: Significantly faster than reference

‚úÖ SECTION END: SPEED BENCHMARK
‚è∞ Completed at: 11:57:12
====================================================================================================


====================================================================================================
üî• SECTION START: CHARACTER LEVEL BENCHMARK
üìã Description: Testing character-level reasoning and morphological alignment
‚è∞ Started at: 11:57:12
====================================================================================================
================================================================================
üî§ CHARACTER-LEVEL REASONING BENCHMARK (CharBench)
================================================================================
Based on academic research - tests character-level understanding
Task                      Word         Target   Expected   Tokens   Efficiency
--------------------------------------------------------------------------------
Count 'r' in 'strawberry' strawberry   r        3          1        3.00x
Count 'l' in 'hello'      hello        l        2          1        1.00x
Count 'a' in 'banana'     banana       a        3          1        1.00x
Count 's' in 'assessment' assessment   s        4          1        1.00x
Find first 'o' in 'hello' hello        o        4          1        1.00x
Find first 'a' in 'banana' banana       a        1          1        1.00x
Find first 'e' in 'development' development  e        1          1        1.00x
============================================================
CHARACTER-LEVEL BENCHMARK SUMMARY
============================================================
Lower token counts generally correlate with better character-level performance
This benchmark assesses tokenizer's suitability for character-aware tasks

‚úÖ SECTION END: CHARACTER LEVEL BENCHMARK
‚è∞ Completed at: 11:57:12
====================================================================================================


====================================================================================================
üî• SECTION START: ROBUSTNESS BENCHMARK
üìã Description: Testing edge case handling and domain robustness
‚è∞ Started at: 11:57:12
====================================================================================================
================================================================================
üõ°Ô∏è  ROBUSTNESS AND EDGE CASE BENCHMARK
================================================================================
Tests challenging inputs that commonly cause production failures
Test Case            Input                          Tokens   Success  Time (ms)
---------------------------------------------------------------------------
Multiple spaces      word1    word2    word3        5        ‚úÖ        0.01
Mixed whitespace     word1		word2
word3            5        ‚úÖ        0.01
Leading/trailing        leading and trailing        4        ‚úÖ        0.01
Unicode              caf√© na√Øve r√©sum√© üöÄ üéØ ‚úÖ        6        ‚úÖ        0.03
Punctuation heavy    Hello!!! What??? Yes... No-... 14       ‚úÖ        0.02
Mixed symbols        @#$%^&*()[]{}|\:;"'<>,./?      1        ‚úÖ        0.01
Repeated chars       aaaaaaaaaaaaaaaaaaaaaaaaaaa... 1        ‚úÖ        0.01
Long identifier      very_long_variable_name_tha... 1        ‚úÖ        0.01
Long URL             https://www.example.com/ver... 32       ‚úÖ        0.03
Empty string                                        0        ‚úÖ        0.00
Single char          a                              1        ‚úÖ        0.00
Single space                                        1        ‚úÖ        0.00
Large numbers        123456789012345678901234567890 1        ‚úÖ        0.01
Scientific notation  1.23e-45 6.78e+123             9        ‚úÖ        0.01
Mixed numeric        v1.2.3-beta.4+build.567.890    5        ‚úÖ        0.01
============================================================
ROBUSTNESS BENCHMARK SUMMARY
============================================================
Success rate: 100.0%
Average processing time: 0.01ms
üèÜ EXCELLENT: Highly robust tokenizer
================================================================================
üß™ ADVANCED BENCHMARKS (Latency/Throughput/Efficiency/Scaling)
================================================================================
Token efficiency (compression ratio hyper/tiktoken): 0.719 ‚úÖ
Latency percentiles (seconds per batch; p50/p95/p99):
latency_small: hyper={'p50':0.000012,'p95':0.000013,'p99':0.000013}  tiktoken={'p50':0.000103,'p95':0.000108,'p99':0.000108}
latency_medium: hyper={'p50':0.000006,'p95':0.000007,'p99':0.000007}  tiktoken={'p50':0.001462,'p95':0.001494,'p99':0.001494}
latency_large: hyper={'p50':0.000025,'p95':0.000030,'p99':0.000030}  tiktoken={'p50':0.039242,'p95':0.039818,'p99':0.039819}
Throughput (mixed inputs) MB/s: hyper=2908.51, tiktoken=2.04
Throughput (many short) MB/s: hyper=116.96, tiktoken=7.25
Success + Determinism: hyper={'ok': True}, tiktoken={'ok': True}
Peak memory (bytes): hyper={'supported': False}, tiktoken={'supported': False}
Scaling (ns/byte across sizes):
{'hyper': [{'bytes': 1428, 'time_s': 0.00016599998343735933, 'ns_per_byte': 165.99998343735933}, {'bytes': 14303, 'time_s': 0.0011008330038748682, 'ns_per_byte': 110.08330038748682}, {'bytes': 143100, 'time_s': 0.011075208021793514, 'ns_per_byte': 110.75208021793514}, {'bytes': 1431028, 'time_s': 0.11479145899647847, 'ns_per_byte': 114.79145899647847}]}
{'tiktoken': [{'bytes': 1428, 'time_s': 0.0001770000089891255, 'ns_per_byte': 177.0000089891255}, {'bytes': 14303, 'time_s': 0.0011238339939154685, 'ns_per_byte': 112.38339939154685}, {'bytes': 143100, 'time_s': 0.010914540966041386, 'ns_per_byte': 109.14540966041386}, {'bytes': 1431028, 'time_s': 0.11007304198574275, 'ns_per_byte': 110.07304198574275}]}

====================================================================================================
üî• SECTION START: FINAL ASSESSMENT
üìã Description: Overall benchmark results and grading
‚è∞ Started at: 11:57:19
====================================================================================================
================================================================================
üèÜ FINAL OVERALL ASSESSMENT
================================================================================
Overall compression ratio: 0.607
Overall success rate: 100.0%
üéØ FINAL GRADE: A+ (Industry Leading)
üìã RECOMMENDATIONS:
‚Ä¢ Excellent performance! Consider optimizing speed further
‚úÖ BENCHMARK COMPLETE - Results ready for production evaluation

‚úÖ SECTION END: FINAL ASSESSMENT
üìä Summary: Grade: A+ (Industry Leading), Tests: 22, Success Rate: 100.0% if 'overall_success_rate' in locals() else 'N/A'
‚è∞ Completed at: 11:57:19
====================================================================================================


‚úÖ SECTION END: COMPREHENSIVE BENCHMARK
üìä Summary: Completed 22 total tests
‚è∞ Completed at: 11:57:19
====================================================================================================

üìä Detailed results saved to: logs/benchmark_results_20250812_115719.json
Detailed results saved to JSON: logs/benchmark_results_20250812_115719.json

====================================================================================================
üéâ TOKENIZER BENCHMARK SESSION COMPLETED SUCCESSFULLY
====================================================================================================
üìä Total tests executed: 22
‚è∞ Session ended at: 2025-08-12 11:57:19.730686
üìù Log file: logs/tokenizer_benchmark_20250812_115712.log
====================================================================================================
