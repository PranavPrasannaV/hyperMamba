====================================================================================================
üöÄ TOKENIZER BENCHMARK SESSION STARTED
====================================================================================================
üìÖ Timestamp: 2025-08-25 16:12:26.241868
üìù Log file: logs/tokenizer_benchmark_20250825_161226.log
üêç Python version: 3.13.5 (v3.13.5:6cb20a219a8, Jun 11 2025, 12:23:45) [Clang 16.0.0 (clang-1600.0.26.6)]
üíª Working directory: /Users/aadisaraf/Documents/hyperMamba
====================================================================================================

====================================================================================================
üî• SECTION START: COMPREHENSIVE BENCHMARK
üìã Description: Full industry-standard tokenizer evaluation suite
‚è∞ Started at: 16:12:26
====================================================================================================
üè¢ OFFICIAL INDUSTRY-STANDARD TOKENIZER BENCHMARK SUITE
================================================================================
Comprehensive evaluation using methodologies from tech giants
Based on research from OpenAI, Google, Meta, and academic institutions
================================================================================

====================================================================================================
üî• SECTION START: COMPRESSION BENCHMARK
üìã Description: Testing compression efficiency vs reference tokenizer
‚è∞ Started at: 16:12:26
====================================================================================================
================================================================================
üìä COMPRESSION EFFICIENCY BENCHMARK
================================================================================
Primary metric used by OpenAI, Google, Meta for tokenizer evaluation
Test 1: The quick brown fox jumps over the lazy dog repeatedly and e...
  Reference (tiktoken)     ‚Üí Tokens:  13, Time:  0.35ms
  HyperTokenizer16k        ‚Üí Tokens:   8, Time:  0.03ms
  Compression Ratio: 0.615 ‚úÖ
Test 2: Natural language processing and artificial intelligence revo...
  Reference (tiktoken)     ‚Üí Tokens:  16, Time:  0.03ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.03ms
  Compression Ratio: 0.875 ‚úÖ
Test 3: In the realm of quantum computing, superposition and entangl...
  Reference (tiktoken)     ‚Üí Tokens:  18, Time:  0.05ms
  HyperTokenizer16k        ‚Üí Tokens:  11, Time:  0.03ms
  Compression Ratio: 0.611 ‚úÖ
Test 4: def fibonacci(n): return n if n <= 1 else fibonacci(n-1) + f...
  Reference (tiktoken)     ‚Üí Tokens:  23, Time:  0.03ms
  HyperTokenizer16k        ‚Üí Tokens:  13, Time:  0.02ms
  Compression Ratio: 0.565 ‚úÖ
Test 5: import torch; model = torch.nn.TransformerEncoder(layers=6, ...
  Reference (tiktoken)     ‚Üí Tokens:  20, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  15, Time:  0.03ms
  Compression Ratio: 0.750 ‚úÖ
Test 6: const apiResponse = await fetch('/api/users').then(res => re...
  Reference (tiktoken)     ‚Üí Tokens:  16, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  12, Time:  0.03ms
  Compression Ratio: 0.750 ‚úÖ
Test 7: public class DataProcessor { private final Config config; }
  Reference (tiktoken)     ‚Üí Tokens:  11, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:   6, Time:  0.02ms
  Compression Ratio: 0.545 ‚úÖ
Test 8: Visit https://www.example.com/docs/api/v2/reference for comp...
  Reference (tiktoken)     ‚Üí Tokens:  14, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.03ms
  Compression Ratio: 1.000 ‚ùå
Test 9: <div class='container'><h1>Welcome</h1><p>Get started today!...
  Reference (tiktoken)     ‚Üí Tokens:  23, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:   5, Time:  0.02ms
  Compression Ratio: 0.217 ‚úÖ
Test 10: body { font-family: Arial, sans-serif; margin: 0; padding: 2...
  Reference (tiktoken)     ‚Üí Tokens:  22, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.02ms
  Compression Ratio: 0.636 ‚úÖ
Test 11: The algorithm achieves O(n log n) time complexity with optim...
  Reference (tiktoken)     ‚Üí Tokens:  14, Time:  0.03ms
  HyperTokenizer16k        ‚Üí Tokens:   9, Time:  0.02ms
  Compression Ratio: 0.643 ‚úÖ
Test 12: Neural networks utilize backpropagation for gradient-based o...
  Reference (tiktoken)     ‚Üí Tokens:  12, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  10, Time:  0.02ms
  Compression Ratio: 0.833 ‚úÖ
Test 13: DNA sequences: ATCGATCGATCG, RNA transcription: AUCGAUCGAUCG
  Reference (tiktoken)     ‚Üí Tokens:  20, Time:  0.01ms
  HyperTokenizer16k        ‚Üí Tokens:   6, Time:  0.02ms
  Compression Ratio: 0.300 ‚úÖ
Test 14: SELECT * FROM users WHERE active = 1 ORDER BY created_at DES...
  Reference (tiktoken)     ‚Üí Tokens:  17, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:   9, Time:  0.02ms
  Compression Ratio: 0.529 ‚úÖ
Test 15: {"name": "John", "age": 30, "email": "john@example.com", "ac...
  Reference (tiktoken)     ‚Üí Tokens:  25, Time:  0.03ms
  HyperTokenizer16k        ‚Üí Tokens:  22, Time:  0.03ms
  Compression Ratio: 0.880 ‚úÖ
Test 16: Version 2.1.3-beta.4 released with performance improvements ...
  Reference (tiktoken)     ‚Üí Tokens:  17, Time:  0.03ms
  HyperTokenizer16k        ‚Üí Tokens:   8, Time:  0.04ms
  Compression Ratio: 0.471 ‚úÖ
Test 17: Processing 1,234,567 records at 99.7% accuracy with 0.003ms ...
  Reference (tiktoken)     ‚Üí Tokens:  23, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:   7, Time:  0.02ms
  Compression Ratio: 0.304 ‚úÖ
Test 18: User ID: usr_1234567890, Session: tok_abcdef123456, Expires:...
  Reference (tiktoken)     ‚Üí Tokens:  35, Time:  0.05ms
  HyperTokenizer16k        ‚Üí Tokens:  15, Time:  0.03ms
  Compression Ratio: 0.429 ‚úÖ
Test 19: Phone: +1-555-123-4567, Email: support@company.com, Website:...
  Reference (tiktoken)     ‚Üí Tokens:  25, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.03ms
  Compression Ratio: 0.560 ‚úÖ
Test 20: Error 404: Page not found. Please check the URL https://exam...
  Reference (tiktoken)     ‚Üí Tokens:  22, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  14, Time:  0.03ms
  Compression Ratio: 0.636 ‚úÖ
Test 21: Meeting scheduled for 2024-01-15 at 2:30 PM in Conference Ro...
  Reference (tiktoken)     ‚Üí Tokens:  27, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  16, Time:  0.03ms
  Compression Ratio: 0.593 ‚úÖ
Test 22: Log entry [2024-01-15 14:30:25] INFO: User authentication su...
  Reference (tiktoken)     ‚Üí Tokens:  26, Time:  0.02ms
  HyperTokenizer16k        ‚Üí Tokens:  16, Time:  0.03ms
  Compression Ratio: 0.615 ‚úÖ
============================================================
COMPRESSION BENCHMARK SUMMARY
============================================================
Total tests: 22
Success rate: 100.0%
Average compression ratio: 0.607
Median compression ratio: 0.613
Best compression ratio: 0.217
Worst compression ratio: 1.000
Average encode time: 0.03ms
üèÜ EXCELLENT: Significantly better compression than reference

‚úÖ SECTION END: COMPRESSION BENCHMARK
‚è∞ Completed at: 16:12:26
====================================================================================================


====================================================================================================
üî• SECTION START: SPEED BENCHMARK
üìã Description: Testing encoding/decoding performance
‚è∞ Started at: 16:12:26
====================================================================================================
================================================================================
‚ö° SPEED PERFORMANCE BENCHMARK
================================================================================
Critical metric for production deployment in tech companies
Test Name       Length   HyperTokenizer  Tiktoken     Speedup
----------------------------------------------------------------------
Short text      12       0.00            0.00         1.12      x
Medium text     440      0.01            0.04         3.81      x
Long text       2450     0.12            0.16         1.34      x
Code snippet    1220     0.05            0.18         3.89      x
JSON data       1200     0.04            0.15         3.36      x
URL heavy       1475     0.04            0.12         3.22      x
Mixed content   1095     0.05            0.13         2.61      x
============================================================
SPEED BENCHMARK SUMMARY
============================================================
Average speedup vs tiktoken: 2.77x
üèÜ EXCELLENT: Significantly faster than reference

‚úÖ SECTION END: SPEED BENCHMARK
‚è∞ Completed at: 16:12:26
====================================================================================================


====================================================================================================
üî• SECTION START: CHARACTER LEVEL BENCHMARK
üìã Description: Testing character-level reasoning and morphological alignment
‚è∞ Started at: 16:12:26
====================================================================================================
================================================================================
üî§ CHARACTER-LEVEL REASONING BENCHMARK (CharBench)
================================================================================
Based on academic research - tests character-level understanding
Task                      Word         Target   Expected   Tokens   Efficiency
--------------------------------------------------------------------------------
Count 'r' in 'strawberry' strawberry   r        3          1        3.00x
Count 'l' in 'hello'      hello        l        2          1        1.00x
Count 'a' in 'banana'     banana       a        3          1        1.00x
Count 's' in 'assessment' assessment   s        4          1        1.00x
Find first 'o' in 'hello' hello        o        4          1        1.00x
Find first 'a' in 'banana' banana       a        1          1        1.00x
Find first 'e' in 'development' development  e        1          1        1.00x
============================================================
CHARACTER-LEVEL BENCHMARK SUMMARY
============================================================
Lower token counts generally correlate with better character-level performance
This benchmark assesses tokenizer's suitability for character-aware tasks

‚úÖ SECTION END: CHARACTER LEVEL BENCHMARK
‚è∞ Completed at: 16:12:26
====================================================================================================


====================================================================================================
üî• SECTION START: ROBUSTNESS BENCHMARK
üìã Description: Testing edge case handling and domain robustness
‚è∞ Started at: 16:12:26
====================================================================================================
================================================================================
üõ°Ô∏è  ROBUSTNESS AND EDGE CASE BENCHMARK
================================================================================
Tests challenging inputs that commonly cause production failures
Test Case            Input                          Tokens   Success  Time (ms)
---------------------------------------------------------------------------
Multiple spaces      word1    word2    word3        5        ‚úÖ        0.01
Mixed whitespace     word1		word2
word3            5        ‚úÖ        0.01
Leading/trailing        leading and trailing        4        ‚úÖ        0.01
Unicode              caf√© na√Øve r√©sum√© üöÄ üéØ ‚úÖ        6        ‚úÖ        0.02
Punctuation heavy    Hello!!! What??? Yes... No-... 14       ‚úÖ        0.02
Mixed symbols        @#$%^&*()[]{}|\:;"'<>,./?      1        ‚úÖ        0.01
Repeated chars       aaaaaaaaaaaaaaaaaaaaaaaaaaa... 1        ‚úÖ        0.02
Long identifier      very_long_variable_name_tha... 1        ‚úÖ        0.01
Long URL             https://www.example.com/ver... 32       ‚úÖ        0.03
Empty string                                        0        ‚úÖ        0.00
Single char          a                              1        ‚úÖ        0.00
Single space                                        1        ‚úÖ        0.00
Large numbers        123456789012345678901234567890 1        ‚úÖ        0.01
Scientific notation  1.23e-45 6.78e+123             9        ‚úÖ        0.01
Mixed numeric        v1.2.3-beta.4+build.567.890    5        ‚úÖ        0.01
============================================================
ROBUSTNESS BENCHMARK SUMMARY
============================================================
Success rate: 100.0%
Average processing time: 0.01ms
üèÜ EXCELLENT: Highly robust tokenizer
================================================================================
üß™ ADVANCED BENCHMARKS (Latency/Throughput/Efficiency/Scaling)
================================================================================
Token efficiency (compression ratio hyper/tiktoken): 0.719 ‚úÖ
Latency percentiles (seconds per batch; p50/p95/p99):
latency_small: hyper={'p50':0.000012,'p95':0.000016,'p99':0.000016}  tiktoken={'p50':0.000088,'p95':0.000096,'p99':0.000097}
latency_medium: hyper={'p50':0.000005,'p95':0.000007,'p99':0.000007}  tiktoken={'p50':0.001390,'p95':0.001627,'p99':0.001635}
latency_large: hyper={'p50':0.000026,'p95':0.000028,'p99':0.000028}  tiktoken={'p50':0.037314,'p95':0.038774,'p99':0.038783}
Throughput (mixed inputs) MB/s: hyper=3082.81, tiktoken=2.10
Throughput (many short) MB/s: hyper=126.35, tiktoken=7.03
Success + Determinism: hyper={'ok': True}, tiktoken={'ok': True}
Peak memory (bytes): hyper={'supported': True, 'baseline_bytes': 142245888, 'peak_bytes': 142245888, 'delta_bytes': 0}, tiktoken={'supported': True, 'baseline_bytes': 142245888, 'peak_bytes': 142245888, 'delta_bytes': 0}
Scaling (ns/byte across sizes):
{'hyper': [{'bytes': 1428, 'time_s': 0.00017574999947100878, 'ns_per_byte': 175.74999947100878}, {'bytes': 14303, 'time_s': 0.0011119590053567663, 'ns_per_byte': 111.19590053567663}, {'bytes': 143100, 'time_s': 0.01096566699561663, 'ns_per_byte': 109.6566699561663}, {'bytes': 1431028, 'time_s': 0.11094495900033507, 'ns_per_byte': 110.94495900033506}]}
{'tiktoken': [{'bytes': 1428, 'time_s': 0.00017358300101477653, 'ns_per_byte': 173.58300101477653}, {'bytes': 14303, 'time_s': 0.0010982909880112857, 'ns_per_byte': 109.82909880112857}, {'bytes': 143100, 'time_s': 0.01079241700062994, 'ns_per_byte': 107.92417000629939}, {'bytes': 1431028, 'time_s': 0.11095862499496434, 'ns_per_byte': 110.95862499496432}]}

====================================================================================================
üî• SECTION START: FINAL ASSESSMENT
üìã Description: Overall benchmark results and grading
‚è∞ Started at: 16:12:33
====================================================================================================
================================================================================
üèÜ FINAL OVERALL ASSESSMENT
================================================================================
Overall compression ratio: 0.607
Overall success rate: 100.0%
üéØ FINAL GRADE: A+ (Industry Leading)
üìã RECOMMENDATIONS:
‚Ä¢ Excellent performance! Consider optimizing speed further
‚úÖ BENCHMARK COMPLETE - Results ready for production evaluation

‚úÖ SECTION END: FINAL ASSESSMENT
üìä Summary: Grade: A+ (Industry Leading), Tests: 22, Success Rate: 100.0% if 'overall_success_rate' in locals() else 'N/A'
‚è∞ Completed at: 16:12:33
====================================================================================================


‚úÖ SECTION END: COMPREHENSIVE BENCHMARK
üìä Summary: Completed 22 total tests
‚è∞ Completed at: 16:12:33
====================================================================================================

üìä Detailed results saved to: logs/benchmark_results_20250825_161233.json
Detailed results saved to JSON: logs/benchmark_results_20250825_161233.json

====================================================================================================
üéâ TOKENIZER BENCHMARK SESSION COMPLETED SUCCESSFULLY
====================================================================================================
üìä Total tests executed: 22
‚è∞ Session ended at: 2025-08-25 16:12:33.703259
üìù Log file: logs/tokenizer_benchmark_20250825_161226.log
====================================================================================================
